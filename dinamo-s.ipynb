{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9073cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add import statements here\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0220c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small epsilon value to prevent division by zero\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a79f62-48af-41bc-8643-03357a54d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_init(nb_bins: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Initializes the reference histogram (mu) and its per-bin Poisson uncertainties (sigma_mu_p).\n",
    "\n",
    "    Args:\n",
    "        nb_bins: The number of bins in the histograms\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - mu0 (np.ndarray): The initial normalized uniform reference histogram [7].\n",
    "            - sigma_mu0_p (np.ndarray): The initial bin-wise Poisson uncertainty (standard deviation) for mu0 [7].\n",
    "    \"\"\"\n",
    "    # Initialize mu as a uniform distribution, normalized to unity\n",
    "    mu0 = np.full(nb_bins, 1.0 / nb_bins, dtype=float)\n",
    "    I_mu0 = np.sum(mu0)\n",
    "\n",
    "    # Compute bin-wise Poisson uncertainties for the initial reference.\n",
    "    variance_mu0_p = mu0 / I_mu0 - (mu0**2) / I_mu0\n",
    "    # Ensure variance is non-negative to avoid sqrt of negative numbers, clamping if necessary\n",
    "    variance_mu0_p = np.maximum(variance_mu0_p, EPSILON)\n",
    "    sigma_mu0_p = np.sqrt(variance_mu0_p)\n",
    "\n",
    "    return mu0, sigma_mu0_p, I_mu0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5449b06-621e-4d76-8919-992ba5945a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_uncertainty(x_tilde_i: np.ndarray, i_x_i: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the bin-wise Poisson uncertainty for a normalized histogram x_tilde_i.\n",
    "    \n",
    "    Args:\n",
    "        x_tilde_i: The normalized histogram (probabilities per bin) for the current run.\n",
    "        i_x_i: The sum of original (unnormalized) counts for the current histogram.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Bin-wise Poisson uncertainty (standard deviation) for x_tilde_i.\n",
    "    \"\"\"\n",
    "    if i_x_i <= EPSILON: # Handle cases where there are no events in the histogram\n",
    "        return np.full_like(x_tilde_i, np.inf) # Return large uncertainty\n",
    "    \n",
    "    # Calculate variance using the specific formula provided\n",
    "    variance_per_bin = x_tilde_i / i_x_i - (x_tilde_i**2) / i_x_i\n",
    "    \n",
    "    # Ensure variance is non-negative, clamping if necessary (e.g., due to floating point precision or zero counts)\n",
    "    variance_per_bin = np.maximum(variance_per_bin, EPSILON) \n",
    "    \n",
    "    return np.sqrt(variance_per_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee1ae05-60e8-4e12-836a-3ae6b9ba4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_init(alpha: float, mu0: np.ndarray, sigma_mu0_p: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Initializes the supporting variables (accumulators) for the Exponentially Weighted Moving Average (EWMA) process.\n",
    "    These accumulators help in efficiently updating the reference mean and variance.\n",
    "    \n",
    "    Args:\n",
    "        alpha: The smoothing factor for EWMA. It determines the weight assigned to history.\n",
    "        mu0: The initial normalized reference histogram.\n",
    "        sigma_mu0_p: The initial bin-wise Poisson uncertainty (standard deviation) for mu0.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple containing the initialized EWMA accumulators:\n",
    "            - W0 (np.ndarray): Initial weighted sum of inverse variances.\n",
    "            - S_mu0 (np.ndarray): Initial weighted sum of histograms.\n",
    "            - S_sigma_mu0 (np.ndarray): Initial weighted sum of squared deviations.\n",
    "    \"\"\"\n",
    "    # omega0 is a bin-wise weight inversely proportional to sigma_mu0_p squared (variance) [11]\n",
    "    # Add EPSILON to prevent division by zero for very small uncertainties.\n",
    "    omega0 = 1.0 / (sigma_mu0_p**2 + EPSILON)\n",
    "    \n",
    "    W0 = (1.0 - alpha) * omega0\n",
    "    S_mu0 = (1.0 - alpha) * omega0 * mu0\n",
    "    S_sigma_mu0 = (1.0 - alpha) * omega0 * (sigma_mu0_p**2)\n",
    "    \n",
    "    return W0, S_mu0, S_sigma_mu0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9443426c-eb6e-48bf-a53f-fd2af69afd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chi2_pull(x_tilde_i: np.ndarray, mu_i: np.ndarray, \n",
    "                       sigma_mu_i: np.ndarray, sigma_x_tilde_i_p: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Computes the reduced chi-squared anomaly score and bin-wise pull values for a run.\n",
    "    \n",
    "    Args:\n",
    "        x_tilde_i: Normalized histogram for the current run.\n",
    "        mu_i: Current reference histogram.\n",
    "        sigma_mu_i: Current bin-wise uncertainty (standard deviation) of the reference.\n",
    "        sigma_x_tilde_i_p: Bin-wise Poisson uncertainty (standard deviation) for x_tilde_i.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - chi2_nu (float): The reduced chi-squared anomaly score.\n",
    "            - pull (np.ndarray): Bin-wise pull values, representing deviations from the reference.\n",
    "    \"\"\"\n",
    "    nb_bins = len(x_tilde_i)\n",
    "    \n",
    "    # Denominator for chi2 and pull, summing the variances of the run and the reference.\n",
    "    denominator = (sigma_x_tilde_i_p**2) + (sigma_mu_i**2)\n",
    "    # Add EPSILON to prevent division by zero for any bin.\n",
    "    denominator = np.maximum(denominator, EPSILON)\n",
    "    \n",
    "    # Numerator for chi2_nu: squared difference between current run and reference\n",
    "    chi2_numerator_per_bin = (x_tilde_i - mu_i)**2\n",
    "    \n",
    "    # Reduced chi-squared statistic, averaged over bins\n",
    "    chi2_nu = (1.0 / nb_bins) * np.sum(chi2_numerator_per_bin / denominator)\n",
    "    \n",
    "    # Bin-wise pull values [11, 14]\n",
    "    pull = (x_tilde_i - mu_i) / np.sqrt(denominator)\n",
    "    \n",
    "    return chi2_nu, pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f00c9bf-20c2-4d94-8d04-c5c8badde0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_reference(alpha: float, x_tilde_i: np.ndarray, I_x_i: float, \n",
    "                       mu_i: np.ndarray, sigma_mu_i: np.ndarray, \n",
    "                       W_i: np.ndarray, S_mu_i: np.ndarray, S_sigma_mu_i: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Updates the reference histogram (mu) and its uncertainty (sigma_mu) using EWMA.\n",
    "    This function is called exclusively when a run is confirmed to be \"good\".\n",
    "    \n",
    "    Args:\n",
    "        alpha: The smoothing factor for EWMA.\n",
    "        x_tilde_i: The normalized histogram of the current good run.\n",
    "        I_x_i: The original total event count for the current good run.\n",
    "        mu_i: The current reference histogram.\n",
    "        sigma_mu_i: The current bin-wise uncertainty (standard deviation) of the reference.\n",
    "        W_i, S_mu_i, S_sigma_mu_i: The current EWMA accumulators.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple containing the updated accumulators and reference:\n",
    "            - mu_i_plus_1 (np.ndarray): The new reference histogram.\n",
    "            - sigma_mu_i_plus_1 (np.ndarray): The new reference uncertainty.\n",
    "            - W_i_plus_1 (np.ndarray)\n",
    "            - S_mu_i_plus_1 (np.ndarray)\n",
    "            - S_sigma_mu_i_plus_1 (np.ndarray)\n",
    "    \"\"\"\n",
    "    # Calculate Poisson uncertainty for the current good run's normalized histogram\n",
    "    sigma_x_tilde_i_p = poisson_uncertainty(x_tilde_i, I_x_i)\n",
    "    \n",
    "    # Calculate statistical weight omega_i, inversely proportional to the run's variance\n",
    "    omega_i = 1.0 / (sigma_x_tilde_i_p**2 + EPSILON)\n",
    "    \n",
    "    # Update accumulators using the generalized EWMA formulas\n",
    "    W_i_plus_1 = alpha * W_i + (1.0 - alpha) * omega_i\n",
    "    S_mu_i_plus_1 = alpha * S_mu_i + (1.0 - alpha) * omega_i * x_tilde_i\n",
    "    S_sigma_mu_i_plus_1 = alpha * S_sigma_mu_i + (1.0 - alpha) * omega_i * (x_tilde_i - mu_i)**2\n",
    "    \n",
    "    # Compute new reference mu and sigma_mu from updated accumulators\n",
    "    mu_i_plus_1 = S_mu_i_plus_1 / W_i_plus_1\n",
    "    sigma_mu_i_plus_1 = np.sqrt(S_sigma_mu_i_plus_1 / W_i_plus_1)\n",
    "    \n",
    "    return mu_i_plus_1, sigma_mu_i_plus_1, W_i_plus_1, S_mu_i_plus_1, S_sigma_mu_i_plus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61b9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dinamo_s_algorithm(histograms: list[np.ndarray], labels: list[int], \n",
    "                       alpha: float, nb_bins: int) -> dict:\n",
    "    \"\"\"\n",
    "    The main DINAMO-S algorithm for Dynamic and INterpretable Anomaly MOnitoring.\n",
    "    It processes a sequence of histograms, calculates anomaly scores, and adaptively updates\n",
    "    a reference histogram based on 'good' runs.\n",
    "    \n",
    "    Args:\n",
    "        histograms (list[np.ndarray]): A list of 1D numpy arrays, where each array is an unnormalized\n",
    "                                       histogram (counts) for a specific run.\n",
    "        labels (list[int]): A list of ground-truth labels for each run (0 for good, 1 for bad).\n",
    "                            In a real-world scenario, these labels would typically come from human\n",
    "                            shifters or a preceding automated classification step.\n",
    "        alpha (float): The smoothing factor for the EWMA. This parameter controls the trade-off\n",
    "                       between giving more weight to historical data or the most recent good run\n",
    "                       during reference updates. It should be between 0 (exclusive) and 1 (exclusive).\n",
    "        nb_bins (int): The number of bins in each histogram.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing lists of results for each run:\n",
    "            - 'chi2_scores': The reduced chi-squared anomaly score for each run.\n",
    "            - 'pull_values': Bin-wise pull values for each run.\n",
    "            - 'mu_references': The reference histogram (mu) after processing each run.\n",
    "            - 'sigma_mu_references': The uncertainty (sigma_mu) of the reference after processing each run.\n",
    "    \"\"\"\n",
    "    # 1. Initialize the reference histogram (mu), its uncertainty (sigma_mu), and EWMA accumulators\n",
    "    mu_current, sigma_mu_current = reference_init(nb_bins)\n",
    "    W_current, S_mu_current, S_sigma_mu_current = ewma_init(alpha, mu_current, sigma_mu_current)\n",
    "\n",
    "    # Lists to store the results for each run\n",
    "    chi2_scores = []\n",
    "    pull_values = []\n",
    "    mu_references = [mu_current.copy()] # Store the initial reference state\n",
    "    sigma_mu_references = [sigma_mu_current.copy()] # Store the initial uncertainty state\n",
    "\n",
    "    # Iterate through each run (histogram and its label)\n",
    "    for i, (hist_i, label_i) in enumerate(zip(histograms, labels)):\n",
    "        # 1. Normalize the histogram to unity and get its total integral (sum of original counts)\n",
    "        I_x_i = np.sum(hist_i)\n",
    "        if I_x_i <= EPSILON: # Handle cases where a histogram is empty (no events)\n",
    "            x_tilde_i = np.full(nb_bins, 0.0)\n",
    "            sigma_x_tilde_i_p = np.full(nb_bins, np.inf) # Assign infinite uncertainty\n",
    "        else:\n",
    "            x_tilde_i = hist_i / I_x_i\n",
    "            # Compute Poisson uncertainty for the current normalized histogram\n",
    "            sigma_x_tilde_i_p = poisson_uncertainty(x_tilde_i, i_x_i)\n",
    "        \n",
    "        # 2. Compute the anomaly score (reduced chi-squared) and bin-wise pull values\n",
    "        chi2_nu, pull_i = compute_chi2_pull(x_tilde_i, mu_current, sigma_mu_current, sigma_x_tilde_i_p)\n",
    "        \n",
    "        chi2_scores.append(chi2_nu)\n",
    "        pull_values.append(pull_i)\n",
    "        \n",
    "        # 3. Update the reference only if the run is confirmed \"good\" (label_i == 0)\n",
    "        if label_i == 0:\n",
    "            mu_current, sigma_mu_current, W_current, S_mu_current, S_sigma_mu_current = \\\n",
    "                update_reference(alpha, x_tilde_i, I_x_i, \n",
    "                                  mu_current, sigma_mu_current, \n",
    "                                  W_current, S_mu_current, S_sigma_mu_current)\n",
    "        # If the run is \"bad\" (label_i == 1), the reference remains unchanged\n",
    "        \n",
    "        # Store the reference state after processing the current run and potential update\n",
    "        mu_references.append(mu_current.copy())\n",
    "        sigma_mu_references.append(sigma_mu_current.copy())\n",
    "\n",
    "    return {\n",
    "        'chi2_scores': chi2_scores,\n",
    "        'pull_values': pull_values,\n",
    "        'mu_references': mu_references, \n",
    "        'sigma_mu_references': sigma_mu_references\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
